{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11182216,"sourceType":"datasetVersion","datasetId":6979862}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CELL 1: Import All Required Libraries\nimport cv2\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom collections import defaultdict, Counter\nfrom skimage import color, exposure\nfrom sklearn.ensemble import IsolationForest\nfrom scipy.stats.mstats import winsorize\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nprint(\"All libraries imported successfully!\")\nprint(f\"TensorFlow version: {tf.__version__}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-27T09:32:35.382668Z","iopub.execute_input":"2025-12-27T09:32:35.382954Z","iopub.status.idle":"2025-12-27T09:32:50.770280Z","shell.execute_reply.started":"2025-12-27T09:32:35.382931Z","shell.execute_reply":"2025-12-27T09:32:50.769533Z"}},"outputs":[{"name":"stderr","text":"2025-12-27 09:32:37.266229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766827957.454775      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766827957.510007      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766827957.946183      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766827957.946231      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766827957.946234      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766827957.946237      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"All libraries imported successfully!\nTensorFlow version: 2.19.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 2: Color Normalization Functions\n\ndef reinhard_normalize(img, target_means=[148.60, 41.56, 81.44], \n                       target_stds=[41.56, 15.57, 18.44]):\n    \"\"\"\n    Reinhard color normalization to handle stain variation.\n    \"\"\"\n    import warnings\n    warnings.filterwarnings('ignore', message='.*CIE-LAB.*')\n    \n    img_float = img.astype(np.float32) / 255.0 if img.dtype == np.uint8 else img\n    img_lab = color.rgb2lab(img_float)\n    \n    for i in range(3):\n        mean = np.mean(img_lab[:, :, i])\n        std = np.std(img_lab[:, :, i])\n        \n        if std < 1e-6:\n            std = 1.0\n        \n        img_lab[:, :, i] = ((img_lab[:, :, i] - mean) / std) * target_stds[i] + target_means[i]\n    \n    img_lab[:, :, 0] = np.clip(img_lab[:, :, 0], 0, 100)\n    img_lab[:, :, 1] = np.clip(img_lab[:, :, 1], -127, 127)\n    img_lab[:, :, 2] = np.clip(img_lab[:, :, 2], -127, 127)\n    \n    img_normalized = color.lab2rgb(img_lab)\n    img_normalized = np.clip(img_normalized, 0, 1)\n    img_normalized = (img_normalized * 255).astype(np.uint8)\n    \n    return img_normalized\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T09:32:58.106885Z","iopub.execute_input":"2025-12-27T09:32:58.107912Z","iopub.status.idle":"2025-12-27T09:32:58.115115Z","shell.execute_reply.started":"2025-12-27T09:32:58.107879Z","shell.execute_reply":"2025-12-27T09:32:58.114336Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def macenko_normalize(img):\n    \"\"\"\n    Macenko-style normalization for histopathology images.\n    \"\"\"\n    img_float = img.astype(np.float32) / 255.0\n    img_float = np.maximum(img_float, 1e-6)\n    od = -np.log10(img_float)\n    \n    h, w, c = od.shape\n    od_flat = od.reshape(-1, 3)\n    \n    od_threshold = 0.15\n    tissue_mask = np.all(od_flat > od_threshold, axis=1)\n    \n    if np.sum(tissue_mask) < 100:\n        return img\n    \n    od_tissue = od_flat[tissue_mask]\n    od_mean = np.mean(od_tissue, axis=0, keepdims=True)\n    od_std = np.std(od_tissue, axis=0, keepdims=True) + 1e-6\n    \n    target_mean = np.array([[0.7, 0.5, 0.6]])\n    target_std = np.array([[0.15, 0.12, 0.13]])\n    \n    od_normalized = (od_flat - od_mean) / od_std * target_std + target_mean\n    od_normalized = np.maximum(od_normalized, 0)\n    \n    img_normalized = 10 ** (-od_normalized)\n    img_normalized = np.clip(img_normalized, 0, 1)\n    img_normalized = img_normalized.reshape(h, w, c)\n    img_normalized = (img_normalized * 255).astype(np.uint8)\n    \n    return img_normalized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T09:33:24.031617Z","iopub.execute_input":"2025-12-27T09:33:24.031939Z","iopub.status.idle":"2025-12-27T09:33:24.038159Z","shell.execute_reply.started":"2025-12-27T09:33:24.031911Z","shell.execute_reply":"2025-12-27T09:33:24.037355Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def combined_normalize(img, method='both'):\n    if method == 'none':\n        return img\n    \n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    if method == 'reinhard':\n        img_normalized = reinhard_normalize(img_rgb)\n    elif method == 'macenko':\n        img_normalized = macenko_normalize(img_rgb)\n    elif method == 'both':\n        img_normalized = macenko_normalize(img_rgb)\n        img_normalized = reinhard_normalize(img_normalized)\n    else:\n        raise ValueError(f\"Unknown normalization method: {method}\")\n    \n    img_normalized = cv2.cvtColor(img_normalized, cv2.COLOR_RGB2BGR)\n    return img_normalized\n\nprint(\"Normalization functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T09:33:37.114726Z","iopub.execute_input":"2025-12-27T09:33:37.115050Z","iopub.status.idle":"2025-12-27T09:33:37.120699Z","shell.execute_reply.started":"2025-12-27T09:33:37.115026Z","shell.execute_reply":"2025-12-27T09:33:37.119910Z"}},"outputs":[{"name":"stdout","text":"Normalization functions defined!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def generate_tissue_mask(img, morph_kernel_size=5):\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n    \n    kernel = np.ones((morph_kernel_size, morph_kernel_size), np.uint8)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\nprint(\"Tissue mask function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T09:33:50.785731Z","iopub.execute_input":"2025-12-27T09:33:50.786537Z","iopub.status.idle":"2025-12-27T09:33:50.791364Z","shell.execute_reply.started":"2025-12-27T09:33:50.786503Z","shell.execute_reply":"2025-12-27T09:33:50.790702Z"}},"outputs":[{"name":"stdout","text":"Tissue mask function defined!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# CELL 4: Multi-Scale Patch Extraction\n\nPATCH_CONFIGS = [\n    {'size': 224, 'stride': 112, 'scale': 1.0, 'name': '20x'},\n    {'size': 224, 'stride': 112, 'scale': 0.5, 'name': '40x'},\n]\n\nTISSUE_THRESHOLD = 0.7\n\n\ndef extract_patches_multiscale(img, mask, save_dir, slide_id, config, oversample_factor=1):\n    patch_size = config['size']\n    stride = config['stride']\n    scale = config['scale']\n    mag_name = config['name']\n    \n    if scale != 1.0:\n        new_h = int(img.shape[0] * scale)\n        new_w = int(img.shape[1] * scale)\n        img_scaled = cv2.resize(img, (new_w, new_h))\n        mask_scaled = cv2.resize(mask, (new_w, new_h))\n    else:\n        img_scaled = img\n        mask_scaled = mask\n    \n    h, w, _ = img_scaled.shape\n    patch_count = 0\n    \n    for oversample_idx in range(oversample_factor):\n        offset_y = np.random.randint(0, stride // 2) if oversample_idx > 0 else 0\n        offset_x = np.random.randint(0, stride // 2) if oversample_idx > 0 else 0\n        \n        for y in range(offset_y, h - patch_size + 1, stride):\n            for x in range(offset_x, w - patch_size + 1, stride):\n                mask_patch = mask_scaled[y:y+patch_size, x:x+patch_size]\n                \n                if np.mean(mask_patch > 0) < TISSUE_THRESHOLD:\n                    continue\n                \n                patch = img_scaled[y:y+patch_size, x:x+patch_size]\n                name = f\"{slide_id}_{mag_name}_x{x}_y{y}_os{oversample_idx}.png\"\n                cv2.imwrite(os.path.join(save_dir, name), patch)\n                patch_count += 1\n    \n    return patch_count\n\n\ndef process_wsi_enhanced(image_path, label_name, output_root, normalization_method='both',\n                         oversample_factor=1):\n    slide_id = os.path.splitext(os.path.basename(image_path))[0]\n    img = cv2.imread(image_path)\n    \n    if img is None:\n        print(f\"Warning: Could not read {image_path}\")\n        return 0\n    \n    if normalization_method != 'none':\n        img = combined_normalize(img, method=normalization_method)\n    \n    mask = generate_tissue_mask(img)\n    save_dir = os.path.join(output_root, label_name)\n    os.makedirs(save_dir, exist_ok=True)\n    \n    total_patches = 0\n    for config in PATCH_CONFIGS:\n        patches = extract_patches_multiscale(\n            img, mask, save_dir, slide_id, config, oversample_factor\n        )\n        total_patches += patches\n    \n    return total_patches\n\nprint(\"Patch extraction functions defined!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T09:34:13.392177Z","iopub.execute_input":"2025-12-27T09:34:13.392828Z","iopub.status.idle":"2025-12-27T09:34:13.403208Z","shell.execute_reply.started":"2025-12-27T09:34:13.392800Z","shell.execute_reply":"2025-12-27T09:34:13.402616Z"}},"outputs":[{"name":"stdout","text":"Patch extraction functions defined!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# CELL 5: Process All Images and Extract Patches\nDATASET_ROOT = \"/kaggle/input/her2-sish-dataset\"\nPATCH_ROOT = \"/kaggle/working/patches\"\n\nclasses = {\n    \"Amplified Samples\": \"Amplified\",\n    \"Non-Amplified Samples\": \"Non_Amplified\",\n    \"ROI_Normal\": \"ROI_Normal\"\n}\n\noversample_factors = {\n    \"Amplified\": 1,\n    \"Non_Amplified\": 1,\n    \"ROI_Normal\": 3\n}\n\nNORMALIZATION_METHOD = 'both'  # Options: 'reinhard', 'macenko', 'both', 'none'\n\npatch_stats = defaultdict(int)\n\nprint(f\"Using normalization method: {NORMALIZATION_METHOD}\")\n\nfor folder, label in classes.items():\n    folder_path = os.path.join(DATASET_ROOT, folder)\n    if not os.path.exists(folder_path):\n        print(f\"Warning: Folder not found: {folder_path}\")\n        continue\n        \n    img_list = [f for f in os.listdir(folder_path) \n                if f.lower().endswith((\".png\", \".jpg\"))]\n    \n    oversample = oversample_factors[label]\n    \n    for img_name in tqdm(img_list, desc=f\"Processing {label} (OS={oversample})\", ncols=100):\n        num_patches = process_wsi_enhanced(\n            os.path.join(folder_path, img_name),\n            label,\n            PATCH_ROOT,\n            normalization_method=NORMALIZATION_METHOD,\n            oversample_factor=oversample\n        )\n        patch_stats[label] += num_patches\n\nprint(\"\\nPatch Extraction Statistics\")\nfor label, count in patch_stats.items():\n    print(f\"{label}: {count} patches\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T09:34:54.658260Z","iopub.execute_input":"2025-12-27T09:34:54.658566Z","iopub.status.idle":"2025-12-27T10:51:23.030234Z","shell.execute_reply.started":"2025-12-27T09:34:54.658539Z","shell.execute_reply":"2025-12-27T10:51:23.029623Z"}},"outputs":[{"name":"stdout","text":"Using normalization method: both\n","output_type":"stream"},{"name":"stderr","text":"Processing Amplified (OS=1): 100%|████████████████████████████████| 113/113 [26:41<00:00, 14.17s/it]\nProcessing Non_Amplified (OS=1): 100%|████████████████████████████| 124/124 [18:54<00:00,  9.15s/it]\nProcessing ROI_Normal (OS=3): 100%|███████████████████████████████| 300/300 [30:52<00:00,  6.18s/it]","output_type":"stream"},{"name":"stdout","text":"\n=== Patch Extraction Statistics ===\nAmplified: 0 patches\nNon_Amplified: 15 patches\nROI_Normal: 115 patches\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# CELL 6: Load and Prepare Datasets\n\n# Clear any cached data\ngc.collect()\ntf.keras.backend.clear_session()\n\nBATCH_SIZE = 32\nIMG_SIZE = (224, 224)\nSEED = 123\n\nprint(f\"Loading datasets from: {PATCH_ROOT}\")\n\n# Load training dataset\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    PATCH_ROOT,\n    validation_split=0.30,\n    subset=\"training\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode='int'\n)\n\n# Load validation+test dataset\ntemp_ds = tf.keras.utils.image_dataset_from_directory(\n    PATCH_ROOT,\n    validation_split=0.30,\n    subset=\"validation\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode='int'\n)\n\n\n# Get class names\nclass_names = train_ds.class_names\nprint(f\"\\nClass names: {class_names}\")\nprint(f\"Number of classes: {len(class_names)}\")\n\n# Split temp into val and test\ntemp_batches = tf.data.experimental.cardinality(temp_ds).numpy()\nval_ds = temp_ds.take(temp_batches // 2)\ntest_ds = temp_ds.skip(temp_batches // 2)\n\n# Optimize datasets\ntrain_ds = train_ds.shuffle(1000).prefetch(tf.data.AUTOTUNE)\nval_ds = val_ds.prefetch(tf.data.AUTOTUNE)\ntest_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n\nprint(\"Datasets loaded and optimized!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T10:53:43.942863Z","iopub.execute_input":"2025-12-27T10:53:43.943193Z","iopub.status.idle":"2025-12-27T10:53:46.735169Z","shell.execute_reply.started":"2025-12-27T10:53:43.943165Z","shell.execute_reply":"2025-12-27T10:53:46.734625Z"}},"outputs":[{"name":"stdout","text":"Loading datasets from: /kaggle/working/patches\nFound 130 files belonging to 3 classes.\nUsing 91 files for training.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766832825.041948      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Found 130 files belonging to 3 classes.\nUsing 39 files for validation.\n\nClass names: ['Amplified', 'Non_Amplified', 'ROI_Normal']\nNumber of classes: 3\nDatasets loaded and optimized!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# CELL 7: Calculate Class Weights\n\n\nall_labels = []\nfor _, labels in train_ds:\n    all_labels.extend(labels.numpy())\n\nall_labels = np.array(all_labels)\nprint(f\"\\nTotal training samples: {len(all_labels)}\")\nprint(f\"Label distribution: {dict(Counter(all_labels))}\")\n\nclass_weights = compute_class_weight(\n    'balanced',\n    classes=np.unique(all_labels),\n    y=all_labels\n)\n\nclass_weight_dict = {i: w for i, w in enumerate(class_weights)}\nprint(f\"Class weights: {class_weight_dict}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T10:53:50.407267Z","iopub.execute_input":"2025-12-27T10:53:50.407886Z","iopub.status.idle":"2025-12-27T10:53:50.592744Z","shell.execute_reply.started":"2025-12-27T10:53:50.407854Z","shell.execute_reply":"2025-12-27T10:53:50.592086Z"}},"outputs":[{"name":"stdout","text":"\nTotal training samples: 91\nLabel distribution: {np.int32(2): 78, np.int32(1): 13}\nClass weights: {0: np.float64(3.5), 1: np.float64(0.5833333333333334)}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# CELL 8: Data Augmentation\n\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomFlip(\"vertical\"),\n    tf.keras.layers.RandomRotation(0.2),\n    tf.keras.layers.RandomZoom(0.15),\n    tf.keras.layers.RandomContrast(0.2),\n    tf.keras.layers.RandomBrightness(0.1),\n], name=\"data_augmentation\")\n\nprint(\"Data augmentation pipeline created!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T10:53:53.841507Z","iopub.execute_input":"2025-12-27T10:53:53.842136Z","iopub.status.idle":"2025-12-27T10:53:53.868066Z","shell.execute_reply.started":"2025-12-27T10:53:53.842108Z","shell.execute_reply":"2025-12-27T10:53:53.867450Z"}},"outputs":[{"name":"stdout","text":"Data augmentation pipeline created!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def _iso_winsor_numpy_flat(x_batch_np, contamination=0.05, win_limit=0.05, random_state=42):\n    if hasattr(x_batch_np, \"numpy\"):\n        x_batch_np = x_batch_np.numpy()\n    x_batch_np = np.asarray(x_batch_np, dtype=np.float32)\n    \n    B, F = x_batch_np.shape\n    \n    clf = IsolationForest(contamination=contamination, random_state=random_state)\n    preds = clf.fit_predict(x_batch_np)\n    \n    out = x_batch_np.copy()\n    for i in range(B):\n        if preds[i] == -1:\n            w = winsorize(out[i], limits=[win_limit, win_limit])\n            out[i] = np.asarray(w, dtype=np.float32)\n    \n    return out\n\n\ndef isolation_winsor_layer(contamination=0.05, win_limit=0.05, random_state=42):\n    def layer_op(x2d):\n        @tf.custom_gradient\n        def _op(x_in):\n            y = tf.py_function(\n                func=lambda z: _iso_winsor_numpy_flat(\n                    z, contamination=contamination,\n                    win_limit=win_limit, random_state=random_state\n                ),\n                inp=[x_in],\n                Tout=tf.float32\n            )\n            y.set_shape(x_in.shape)\n            \n            def grad(dy):\n                return dy\n            return y, grad\n        return _op(x2d)\n    return layer_op\n\nprint(\"Robust outlier filtering layer defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T10:53:55.967807Z","iopub.execute_input":"2025-12-27T10:53:55.968422Z","iopub.status.idle":"2025-12-27T10:53:55.975899Z","shell.execute_reply.started":"2025-12-27T10:53:55.968394Z","shell.execute_reply":"2025-12-27T10:53:55.975038Z"}},"outputs":[{"name":"stdout","text":"Robust outlier filtering layer defined!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# CELL 10: Squeeze-and-Excitation Block\n\ndef squeeze_excitation_block(input_tensor, ratio=16, name='se'):\n    \"\"\"Squeeze-and-Excitation block for channel attention.\"\"\"\n    from tensorflow.keras import layers\n    \n    channels = input_tensor.shape[-1]\n    se = layers.GlobalAveragePooling2D(name=f'{name}_gap')(input_tensor)\n    se = layers.Dense(channels // ratio, activation='relu', name=f'{name}_fc1')(se)\n    se = layers.Dense(channels, activation='sigmoid', name=f'{name}_fc2')(se)\n    se = layers.Reshape((1, 1, channels), name=f'{name}_reshape')(se)\n    output = layers.Multiply(name=f'{name}_multiply')([input_tensor, se])\n    return output\n\nprint(\"SE block function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T10:53:58.984720Z","iopub.execute_input":"2025-12-27T10:53:58.985291Z","iopub.status.idle":"2025-12-27T10:53:58.991387Z","shell.execute_reply.started":"2025-12-27T10:53:58.985263Z","shell.execute_reply":"2025-12-27T10:53:58.990655Z"}},"outputs":[{"name":"stdout","text":"SE block function defined!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# CELL 11: Build Enhanced Model\n\ndef build_enhanced_model(input_shape=(224, 224, 3), num_classes=3, \n                         use_robust_filter=True, contamination=0.05):\n    \n    inputs = layers.Input(shape=input_shape, name='input')\n    \n    x = data_augmentation(inputs)\n    # ❌ REMOVE manual rescaling\n    \n    base_model = EfficientNetB0(\n        include_top=False,\n        weights=\"imagenet\",\n        input_tensor=x\n    )\n    base_model.trainable = False\n    \n    x = base_model.output\n    x = squeeze_excitation_block(x, ratio=16, name='se_post_backbone')\n    x = layers.GlobalAveragePooling2D(name='global_pool')(x)\n    \n    if use_robust_filter:\n        x = layers.Lambda(\n            isolation_winsor_layer(contamination=contamination, win_limit=0.05),\n            name='robust_filter'\n        )(x)\n    \n    x = layers.Dense(256, activation='relu', name='fc1')(x)\n    x = layers.Dropout(0.5, name='dropout1')(x)\n    x = layers.Dense(128, activation='relu', name='fc2')(x)\n    x = layers.Dropout(0.3, name='dropout2')(x)\n    \n    outputs = layers.Dense(num_classes, activation='softmax', name='output')(x)\n    \n    model = models.Model(inputs, outputs, name='HER2_SISH_Classifier')\n    return model\n\n\n\n# Build the model\nmodel = build_enhanced_model(\n    input_shape=(224, 224, 3),\n    num_classes=len(class_names),\n    use_robust_filter=True,\n    contamination=0.05\n)\n\nprint(\"Model built successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:09:47.277568Z","iopub.execute_input":"2025-12-27T11:09:47.278339Z","iopub.status.idle":"2025-12-27T11:09:51.273875Z","shell.execute_reply.started":"2025-12-27T11:09:47.278307Z","shell.execute_reply":"2025-12-27T11:09:51.273110Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\nModel built successfully!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# CELL 12: Compile Model\n\n# Disable problematic TensorFlow optimizers\ntf.config.optimizer.set_experimental_options({\n    'layout_optimizer': False,\n})\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\n\nprint(\"Model compiled!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:11:23.235338Z","iopub.execute_input":"2025-12-27T11:11:23.235702Z","iopub.status.idle":"2025-12-27T11:11:23.253250Z","shell.execute_reply.started":"2025-12-27T11:11:23.235674Z","shell.execute_reply":"2025-12-27T11:11:23.252655Z"}},"outputs":[{"name":"stdout","text":"Model compiled!\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# CELL 13: Define Training Callbacks\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=8,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=4,\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        'best_model.keras',\n        monitor='val_auc',\n        mode='max',\n        save_best_only=True,\n        verbose=1\n    )\n]\n\nprint(\"Callbacks defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:11:25.493549Z","iopub.execute_input":"2025-12-27T11:11:25.494091Z","iopub.status.idle":"2025-12-27T11:11:25.499101Z","shell.execute_reply.started":"2025-12-27T11:11:25.494064Z","shell.execute_reply":"2025-12-27T11:11:25.498404Z"}},"outputs":[{"name":"stdout","text":"Callbacks defined!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# CELL 14: Training Phase 1 - Frozen Backbone\n\nprint(\"Phase 1: Training with Frozen Backbone\")\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=25,\n    callbacks=callbacks,\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\nprint(\"Phase 1 training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T11:11:29.714171Z","iopub.execute_input":"2025-12-27T11:11:29.714889Z","iopub.status.idle":"2025-12-27T11:11:33.944325Z","shell.execute_reply.started":"2025-12-27T11:11:29.714856Z","shell.execute_reply":"2025-12-27T11:11:33.943357Z"}},"outputs":[{"name":"stdout","text":"Phase 1: Training with Frozen Backbone\nEpoch 1/25\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2623799812.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Phase 1: Training with Frozen Backbone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/math.py\u001b[0m in \u001b[0;36msegment_sum\u001b[0;34m(data, segment_ids, num_segments, sorted)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0munique_segment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mnum_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_segment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsorted_segment_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Shape must be at least rank 1 but is rank 0 for '{{node loop_body/UnsortedSegmentSum}} = UnsortedSegmentSum[T=DT_FLOAT, Tindices=DT_INT32, Tnumsegments=DT_INT32](loop_body/GatherV2, loop_body/GatherV2_1, loop_body/UnsortedSegmentSum/num_segments)' with input shapes: [], [?], []."],"ename":"ValueError","evalue":"Shape must be at least rank 1 but is rank 0 for '{{node loop_body/UnsortedSegmentSum}} = UnsortedSegmentSum[T=DT_FLOAT, Tindices=DT_INT32, Tnumsegments=DT_INT32](loop_body/GatherV2, loop_body/GatherV2_1, loop_body/UnsortedSegmentSum/num_segments)' with input shapes: [], [?], [].","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"# CELL 15: Training Phase 2 - Fine-tuning\n\nprint(\"Phase 2: Fine-tuning\")\n\n# Unfreeze last blocks of EfficientNet\nfor layer in model.layers:\n    if isinstance(layer, tf.keras.Model):\n        for sublayer in layer.layers:\n            if 'block6' in sublayer.name or 'block7' in sublayer.name:\n                sublayer.trainable = True\n\n# Recompile with lower learning rate\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.AUC(name='auc', multi_label=False)]\n)\n\nfine_history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=20,\n    callbacks=callbacks,\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\nprint(\"Phase 2 training completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:40:30.845642Z","iopub.execute_input":"2025-12-27T08:40:30.846456Z","iopub.status.idle":"2025-12-27T08:40:35.043560Z","shell.execute_reply.started":"2025-12-27T08:40:30.846423Z","shell.execute_reply":"2025-12-27T08:40:35.042961Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# CELL 16: Plot Training History\n\ndef plot_training_history(history, fine_history):\n    metrics = ['loss', 'accuracy', 'auc']\n    \n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    for idx, metric in enumerate(metrics):\n        train_metric = history.history[metric] + fine_history.history[metric]\n        val_metric = history.history[f'val_{metric}'] + fine_history.history[f'val_{metric}']\n        \n        epochs = range(1, len(train_metric) + 1)\n        \n        axes[idx].plot(epochs, train_metric, 'b-o', label=f'Training', alpha=0.8)\n        axes[idx].plot(epochs, val_metric, 'r--s', label=f'Validation', alpha=0.8)\n        axes[idx].axvline(x=len(history.history[metric]), color='g', \n                         linestyle=':', label='Fine-tuning Start')\n        axes[idx].set_title(f'{metric.upper()}')\n        axes[idx].set_xlabel('Epoch')\n        axes[idx].set_ylabel(metric.capitalize())\n        axes[idx].legend()\n        axes[idx].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\nplot_training_history(history, fine_history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:40:38.293102Z","iopub.execute_input":"2025-12-27T08:40:38.293639Z","iopub.status.idle":"2025-12-27T08:40:38.297902Z","shell.execute_reply.started":"2025-12-27T08:40:38.293611Z","shell.execute_reply":"2025-12-27T08:40:38.297217Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def predict_with_tta(model, images, num_augmentations=5):\n    predictions = []\n    \n    for _ in range(num_augmentations):\n        aug_images = data_augmentation(images, training=True)\n        preds = model.predict(aug_images, verbose=0)\n        predictions.append(preds)\n    \n    avg_predictions = np.mean(predictions, axis=0)\n    return avg_predictions\n\nprint(\"TTA function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:42:43.332877Z","iopub.execute_input":"2025-12-27T08:42:43.333210Z","iopub.status.idle":"2025-12-27T08:42:55.539186Z","shell.execute_reply.started":"2025-12-27T08:42:43.333181Z","shell.execute_reply":"2025-12-27T08:42:55.538131Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1766824973.835076      55 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/HER2_SISH_Classifier_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/419288903.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node GatherV2 defined at (most recent call last):\n<stack traces unavailable>\nDetected at node GatherV2 defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Error in user-defined function passed to MapDataset:22 transformation with iterator: Iterator::Root::Prefetch::ParallelMapV2: indices[0] = 2 is not in [0, 2)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) INVALID_ARGUMENT:  Error in user-defined function passed to MapDataset:22 transformation with iterator: Iterator::Root::Prefetch::ParallelMapV2: indices[0] = 2 is not in [0, 2)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_51518]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node GatherV2 defined at (most recent call last):\n<stack traces unavailable>\nDetected at node GatherV2 defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Error in user-defined function passed to MapDataset:22 transformation with iterator: Iterator::Root::Prefetch::ParallelMapV2: indices[0] = 2 is not in [0, 2)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) INVALID_ARGUMENT:  Error in user-defined function passed to MapDataset:22 transformation with iterator: Iterator::Root::Prefetch::ParallelMapV2: indices[0] = 2 is not in [0, 2)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_51518]","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"# CELL 18: MIL (Multiple Instance Learning) Evaluation\n\ndef mil_topk_with_tta(model, dataset, k=10, use_tta=True):\n    slide_probs = defaultdict(list)\n    slide_labels = {}\n    \n    patch_idx = 0\n    for images, labels in tqdm(dataset, desc=\"MIL Inference\"):\n        if use_tta:\n            preds = predict_with_tta(model, images, num_augmentations=5)\n        else:\n            preds = model.predict(images, verbose=0)\n        \n        for i, pred in enumerate(preds):\n            slide_id = patch_idx // 20\n            slide_probs[slide_id].append(pred)\n            slide_labels[slide_id] = labels[i].numpy()\n            patch_idx += 1\n    \n    y_true, y_pred, y_probs = [], [], []\n    for slide_id in sorted(slide_probs.keys()):\n        probs = slide_probs[slide_id]\n        confidences = [np.max(p) for p in probs]\n        top_indices = np.argsort(confidences)[-k:]\n        top_probs = [probs[i] for i in top_indices]\n        mean_prob = np.mean(top_probs, axis=0)\n        pred_class = np.argmax(mean_prob)\n        \n        y_true.append(slide_labels[slide_id])\n        y_pred.append(pred_class)\n        y_probs.append(mean_prob)\n    \n    return np.array(y_true), np.array(y_pred), np.array(y_probs)\n\nprint(\"MIL function defined!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Evaluating on Test Set with MIL + TTA\")\n\ny_true, y_pred, y_probs = mil_topk_with_tta(model, test_ds, k=10, use_tta=True)\n\nprint(\"\\nClassification Report\")\nprint(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 20: Plot Confusion Matrix\n\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            cbar_kws={'label': 'Count'})\nplt.title('Confusion Matrix - HER2-SISH Classification', fontsize=16, fontweight='bold')\nplt.ylabel('True Label', fontsize=12)\nplt.xlabel('Predicted Label', fontsize=12)\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nEvaluation completed!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 22: Generate Summary Report\nprint(\"FINAL SUMMARY REPORT\")\n\nprint(f\"\\nDataset Information:\")\nprint(f\"  - Total classes: {len(class_names)}\")\nprint(f\"  - Class names: {class_names}\")\nprint(f\"  - Training samples: {len(all_labels)}\")\nprint(f\"  - Class distribution: {dict(Counter(all_labels))}\")\n\nprint(f\"\\nModel Configuration:\")\nprint(f\"  - Architecture: EfficientNetB0 with SE blocks\")\nprint(f\"  - Input shape: (224, 224, 3)\")\nprint(f\"  - Normalization: {NORMALIZATION_METHOD}\")\nprint(f\"  - Robust filtering: Enabled\")\nprint(f\"  - Data augmentation: Enabled\")\n\nprint(f\"\\nTraining Configuration:\")\nprint(f\"  - Batch size: {BATCH_SIZE}\")\nprint(f\"  - Phase 1 epochs: {len(history.history['loss'])}\")\nprint(f\"  - Phase 2 epochs: {len(fine_history.history['loss'])}\")\nprint(f\"  - Class weights: {class_weight_dict}\")\n\nprint(f\"\\nFinal Performance:\")\nprint(f\"  - Test accuracy: {np.mean(y_true == y_pred):.3f}\")\nprint(f\"  - Per-class accuracy:\")\nfor i, class_name in enumerate(class_names):\n    class_mask = y_true == i\n    if np.sum(class_mask) > 0:\n        class_acc = np.mean(y_pred[class_mask] == i)\n        print(f\"    {class_name}: {class_acc:.3f}\")\n\nprint(\"Pipeline completed successfully! ✅\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unfreeze base model for fine-tuning\nfor layer in model.layers:\n    if \"inception_resnet_v2\" in layer.name:\n        layer.trainable = True\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-6), # Extremely low LR\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nfine_history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=15,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:55:19.002540Z","iopub.status.idle":"2025-12-27T06:55:19.003209Z","shell.execute_reply.started":"2025-12-27T06:55:19.003034Z","shell.execute_reply":"2025-12-27T06:55:19.003055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = 3\n\nmodel = build_robust_model(\n    input_shape=(224, 224, 3),\n    num_classes=num_classes,\n    use_robust_filter=True,\n    contamination=0.05\n)\n\n# Compile the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n)\n\n# Display model summary\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:31:32.292715Z","iopub.execute_input":"2025-12-27T08:31:32.293369Z","iopub.status.idle":"2025-12-27T08:31:36.280885Z","shell.execute_reply.started":"2025-12-27T08:31:32.293334Z","shell.execute_reply":"2025-12-27T08:31:36.280256Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"callbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=8,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=4,\n        min_lr=1e-7,\n        verbose=1\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        'best_inception_model.keras',\n        monitor='val_auc',\n        mode='max',\n        save_best_only=True,\n        verbose=1\n    )\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:28:33.957666Z","iopub.execute_input":"2025-12-27T08:28:33.958192Z","iopub.status.idle":"2025-12-27T08:28:33.962943Z","shell.execute_reply.started":"2025-12-27T08:28:33.958165Z","shell.execute_reply":"2025-12-27T08:28:33.962071Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Training Phase 1: Frozen backbone\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=25,\n    callbacks=callbacks,\n    # class_weight=class_weight_dict,  # Uncomment if you have class weights\n    verbose=1\n)\n\n# Training Phase 2: Fine-tuning\nprint(\"\\n=== Phase 2: Fine-tuning ===\")\n\n# Unfreeze the last few layers of InceptionResNetV2\nfor layer in model.layers:\n    if isinstance(layer, tf.keras.Model):  # The InceptionResNetV2 base\n        # Unfreeze from 'mixed_7a' onwards (last few blocks)\n        unfreeze = False\n        for sublayer in layer.layers:\n            if 'mixed_7a' in sublayer.name:\n                unfreeze = True\n            if unfreeze:\n                sublayer.trainable = True\n\n# Recompile with lower learning rate\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n)\n\n# Continue training\nfine_history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=20,\n    callbacks=callbacks,\n    # class_weight=class_weight_dict,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:29:00.268834Z","iopub.execute_input":"2025-12-27T08:29:00.269642Z","iopub.status.idle":"2025-12-27T08:29:00.277306Z","shell.execute_reply.started":"2025-12-27T08:29:00.269602Z","shell.execute_reply":"2025-12-27T08:29:00.276451Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2721039910.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training Phase 1: Frozen backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"],"ename":"NameError","evalue":"name 'train_ds' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}